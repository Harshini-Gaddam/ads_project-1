{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfJAw98yJjxc",
        "outputId": "c5206455-3ddc-46a0-b10b-d726a8b19d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping complete.\n"
          ]
        }
      ],
      "source": [
        "#11\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "# sitejabber URL\n",
        "base_url = \"https://www.sitejabber.com/reviews/uber.com\"\n",
        "page_num = 1\n",
        "max_pages = 110\n",
        "\n",
        "# Open the CSV file\n",
        "with open('uber_reviews.csv', mode='w', newline='', encoding='utf-8') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow(['Review'])\n",
        "\n",
        "    \n",
        "    while page_num <= max_pages:\n",
        "        \n",
        "        url = base_url.format(page_num)\n",
        "\n",
        "        # GET the request and parsing the response through beautiful soup\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Finding the xpath\n",
        "        review_container = soup.find('div', class_='url-reviews__list')\n",
        "        if review_container: \n",
        "            reviews = []\n",
        "            \n",
        "            for review in review_container.find_all('div', class_='review__content'):\n",
        "                review_text = review.find('p').text.strip()\n",
        "                reviews.append(review_text)               \n",
        "            \n",
        "            for review_text in zip(reviews):\n",
        "                writer.writerow(review_text)\n",
        "\n",
        "            page_num += 1\n",
        "            time.sleep(3)\n",
        "        else:\n",
        "            # Exception message\n",
        "            print(f\"Review container not found on page {page_num}.\")\n",
        "            page_num += 1\n",
        "            continue\n",
        "\n",
        "print(\"Scraping complete.\")"
      ]
    }
  ]
}